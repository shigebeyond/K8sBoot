# 使用物理ip来作为master url
# https://blog.csdn.net/cobracanary/article/details/126246695
- set_vars:
#    master_host: hww-pc
#    master_ip: 192.168.1.10
    master_host: mac
    master_ip: 192.168.62.209
# 1主2从
# 主
- app(spark-master):
    - containers:
        master:
          image: bitnami/spark # spark版本是3.2.0
          user: 0 # 指定运行该Pod的user ID, 0为root
          env:
            SPARK_MODE: master
            SPARK_MASTER_HOST: $master_ip
            SPARK_MASTER_PORT: 7077
            SPARK_RPC_AUTHENTICATION_ENABLED: no
            SPARK_RPC_ENCRYPTION_ENABLED: no
            SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
            SPARK_SSL_ENABLED: no
            # hadoop yarn配置+client库，但可惜 pyspark --master yarn 不能进入命令行
            YARN_CONF_DIR: /opt/hadoop-3.2.1/etc
            LD_LIBRARY_PATH: '/opt/hadoop-3.2.1/lib/native/:/opt/bitnami/python/lib/:/opt/bitnami/spark/venv/lib/python3.8/site-packages/numpy.libs/:'
#          ports:
#            - '8080:8080:8080' # spark UI
#            - '7077:7077:7077' # 用于连接spark
#            - '4040:4040:4040' # job执行UI
          ports: '*' # 映射宿主机所有端口，即hostNetwork=true
          volumes:
            - /data/spark/python:/python # 映射/python目录，用于存放pyspark代码，方便运行
            - /data/spark/input:/input
            - /opt/hadoop-3.2.1:/opt/hadoop-3.2.1 # 映射hadoop目录
            - /home/shi/.local/lib/python3.7/site-packages:/opt/bitnami/python/lib/python3.8/site-packages # 映射python库
    # 部署
    - deploy:
        hostname:
        replicas: 1 # 副本数
        nodeSelector: # 节点选择: dict形式
          kubernetes.io/hostname: $master_host
# 从
- app(spark-worker):
    - containers:
        worker:
          image: bitnami/spark
          user: 0 # 指定运行该Pod的user ID, 0为root
          env:
            SPARK_MODE: worker
            SPARK_MASTER_URL: spark://$master_ip:7077
            SPARK_WORKER_PORT: 8081 # 显式指定ui端口
            SPARK_WORKER_MEMORY: 1G
            SPARK_WORKER_CORES: 1
            SPARK_RPC_AUTHENTICATION_ENABLED: no
            SPARK_RPC_ENCRYPTION_ENABLED: no
            SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
            SPARK_SSL_ENABLED: no
          ports:
            - '8081:8081' # spark UI
          volumes:
            - /data/spark/input:/input
    # deamonset
    - ds:
        hostname:


