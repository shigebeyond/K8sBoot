# 使用物理ip来作为master url
# https://blog.csdn.net/cobracanary/article/details/126246695
- set_vars:
#    master_host: hww-pc
#    master_ip: 192.168.1.9
#    home: /home/hww
    master_host: shi-pc
    master_ip: 192.168.61.18
    home: /home/shi
    deploy_master:
      replicas: 1 # 副本数
      nodeSelector: # 节点选择: dict形式
        kubernetes.io/hostname: $master_host
# 1主2从
# 主
- app(spark-master):
    - containers:
        master:
          image: bitnami/spark # spark版本是3.2.0
          user: 0 # 指定运行该Pod的user ID, 0为root
          env:
            SPARK_MODE: master
            SPARK_MASTER_HOST: $master_ip
            SPARK_MASTER_PORT: 7077
            SPARK_RPC_AUTHENTICATION_ENABLED: no
            SPARK_RPC_ENCRYPTION_ENABLED: no
            SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
            SPARK_SSL_ENABLED: no
            # hadoop yarn配置+client库，但可惜 pyspark --master yarn 不能进入命令行
            YARN_CONF_DIR: /opt/hadoop-3.2.1/etc
            HADOOP_CONF_DIR: /opt/hadoop-3.2.1/etc
            LD_LIBRARY_PATH: '/opt/hadoop-3.2.1/lib/native/:/opt/bitnami/python/lib/:/opt/bitnami/spark/venv/lib/python3.8/site-packages/numpy.libs/:'
#          ports:
#            - '8080:8080:8080' # spark UI
#            - '7077:7077:7077' # 用于连接spark
#            - '4040:4040:4040' # job执行UI
          ports: '*' # 映射宿主机所有端口，即hostNetwork=true
          command: /mnt/start.sh
          volumes:
            - nfs://$master_ip/spark:/mnt # 挂载nfs，包含start.sh+jar+脚本
            - /opt/hadoop-3.2.1:/opt/hadoop-3.2.1 # 映射hadoop目录
            - $home/.local/lib/python3.8/site-packages:/.local/lib/python3.8/site-packages # 映射python依赖目录
    # 部署
    - deploy: $deploy_master
# 从
- app(spark-worker):
    - initContainers:
        init:
          command: chmod 0777 -R /output # 授权输出目录写权限，否则无法写入
          volumes:
            - /data/spark/output:/output
    - containers:
        worker:
          image: bitnami/spark
          user: 0 # 指定运行该Pod的user ID, 0为root
          env:
            SPARK_MODE: worker
            SPARK_MASTER_URL: spark://$master_ip:7077
            SPARK_WORKER_PORT: 8081 # 显式指定ui端口
            SPARK_WORKER_MEMORY: 1G
            SPARK_WORKER_CORES: 1
            SPARK_RPC_AUTHENTICATION_ENABLED: no
            SPARK_RPC_ENCRYPTION_ENABLED: no
            SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
            SPARK_SSL_ENABLED: no
          ports:
            - '8081:8081' # spark UI
            - '8082:8082' # 若8081被占用，则会递增
          command: /mnt/start.sh
          volumes:
            - nfs://$master_ip/spark:/mnt # 挂载nfs，包含start.sh+jar+脚本
            - /data/spark/work:/opt/bitnami/spark/work # executor工作目录，有日志
    # deamonset
    - ds:
        hostname:


